>## **루브릭**
>
>|번호|평가문항|상세기준|평가결과|
>|:---:|---|---|:---:|
>|1|프로젝트 1의 회귀모델 예측정확도가 기준 이상 높게 나왔는가?|MSE 손실함수값 3000 이하를 달성|⭐|
>|2|프로젝트 2의 회귀모델 예측정확도가 기준 이상 높게 나왔는가?|RMSE 값 150 이하를 달성|⭐|
>|3|시각화 요구사항이 정확하게 이루어졌는가?|각 프로젝트 진행 과정에서 요구하고 있는 데이터개수 시각화 및 예측결과 시각화를 모두 진행하였다.|⭐|

----------------------------------------------

- 코더 : 김경훈
- 리뷰어 : 신성윤

----------------------------------------------

PRT(PeerReviewTemplate)

- [X] 코드가 정상적으로 동작하고 주어진 문제를 해결했나요?
- [X] 주석을 보고 작성자의 코드가 이해되었나요?
#위 항목에 대한 근거 작성 필수
- [X] 코드가 에러를 유발할 가능성이 있나요?
#위 항목에 대한 근거 작성 필수
- [X] 코드 작성자가 코드를 제대로 이해하고 작성했나요? (직접 인터뷰해보기)
#위 항목에 대한 근거 작성 필수
- [X] 코드가 간결한가요?
#위 항목에 대한 근거 작성 필수

----------------------------------------------

참고 링크 및 코드 개선
- 프로젝트1 9번 step에서, "for i in range(1, 30001):"에서 iteration 횟수가 좀 많은 것처럼 느껴집니다.
```
losses = []

for i in range(1, 30001):
    dw, db = gradient(X_train, W, b, y_train)   
    W -= LEARNING_RATE * dw         
    b -= LEARNING_RATE * db         
    L = loss(df_x, W, b, df_y)            
    losses.append(L)                
    if i % 1000 == 0:
        print('Iteration %d : Loss %0.4f' % (i, L))
```
- LEARNING_RATE = 0.001 셋팅과 3만번의 iter로 loss가 2900까지 떨어졌는데, 제가 LR을 0.5로 iter를 1000번 했을 때 비슷한 손실함수 최적화와 더 낮은 MSE가 나왔습니다. 너무 낮은 LR은 컴퓨팅 리소스를 많이 잡아먹고 또 너무 높은 LR 설정을 dL/dw 미분 최적화 과정에서 local minimum에 수렴하지 못하고 건너뛰어서 무한루프에 빠지는 결과가 나올 수 있다고 합니다.

- 프로젝트2 6번 step에서 계산된 RMSE 값(8.200676982031253e-13)이 너무 낮습니다. 또한 후속 step의 plot된 그래프에서 데이터 분포가 비이상적이라는 사실을 감안할 때, 데이터 처리 과정에서 문제가 있는 것으로 추정됩니다.
- sklearn.model_selection.train_test_split()의 test_size: float or int, default=None이 빠져있습니다. default값인 none으로 되면 어떤 문제가 발생할지 확인이 필요할 것 같습니다.
