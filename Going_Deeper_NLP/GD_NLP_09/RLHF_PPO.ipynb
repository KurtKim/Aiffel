{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f408a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4330ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='./output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='./output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ef8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75b8366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77562c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ba13e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[47311, 10448, 19008,  9792, 11780, 11308, 30190, 10929, 11849, 21663,\n",
      "         44389,  9574, 13799,   458, 14308, 12778, 22469, 20938, 44696,   458,\n",
      "         13799,   458, 14308, 12778, 11756, 18944,   389]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f9862a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "398054b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b120aab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.88s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.000339]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.91it/s, actor_loss=0, critic_loss=0.000339]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.91it/s, actor_loss=0, critic_loss=0.137]   \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.94it/s, actor_loss=0, critic_loss=0.137]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.94it/s, actor_loss=0, critic_loss=0.0068]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.94it/s, actor_loss=0, critic_loss=0.0068]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:19<00:00,  6.36s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.75s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.188, critic_loss=0.0355]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.93it/s, actor_loss=0.188, critic_loss=0.0355]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.93it/s, actor_loss=0.203, critic_loss=0.083] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.92it/s, actor_loss=0.203, critic_loss=0.083]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.92it/s, actor_loss=0.193, critic_loss=0.0545]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.92it/s, actor_loss=0.193, critic_loss=0.0545]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:18<00:00,  6.27s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.68s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0969, critic_loss=0.0104]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.95it/s, actor_loss=0.0969, critic_loss=0.0104]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.95it/s, actor_loss=0.125, critic_loss=0.00261]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=0.125, critic_loss=0.00261]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=0.095, critic_loss=0.0261] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.93it/s, actor_loss=0.095, critic_loss=0.0261]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:18<00:00,  6.08s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.67s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.187, critic_loss=0.0448]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.94it/s, actor_loss=-.187, critic_loss=0.0448]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.94it/s, actor_loss=-.18, critic_loss=0.027]  \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=-.18, critic_loss=0.027]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=-.174, critic_loss=0.0109]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.92it/s, actor_loss=-.174, critic_loss=0.0109]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:18<00:00,  6.16s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.71s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0142, critic_loss=0.000502]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.90it/s, actor_loss=-.0142, critic_loss=0.000502]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.90it/s, actor_loss=-.0207, critic_loss=0.00666] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.92it/s, actor_loss=-.0207, critic_loss=0.00666]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.92it/s, actor_loss=-.0194, critic_loss=0.0217] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.91it/s, actor_loss=-.0194, critic_loss=0.0217]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:18<00:00,  6.01s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.68s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.129, critic_loss=0.0189]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=0.129, critic_loss=0.0189]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=0.14, critic_loss=0.00899]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=0.14, critic_loss=0.00899]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=0.123, critic_loss=0.00144]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s, actor_loss=0.123, critic_loss=0.00144]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:18<00:00,  6.23s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.92s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0091, critic_loss=0.000621]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.85it/s, actor_loss=-.0091, critic_loss=0.000621]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.85it/s, actor_loss=-.00198, critic_loss=0.00473]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.84it/s, actor_loss=-.00198, critic_loss=0.00473]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.84it/s, actor_loss=-.00322, critic_loss=0.011]  \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s, actor_loss=-.00322, critic_loss=0.011]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:19<00:00,  6.49s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.18s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0827, critic_loss=0.00979]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.86it/s, actor_loss=-.0827, critic_loss=0.00979]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.86it/s, actor_loss=-.072, critic_loss=0.0035]  \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.84it/s, actor_loss=-.072, critic_loss=0.0035]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.84it/s, actor_loss=-.0769, critic_loss=0.00108]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s, actor_loss=-.0769, critic_loss=0.00108]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:20<00:00,  6.72s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.93s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.000464, critic_loss=0.000269]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.000464, critic_loss=0.000269]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.0182, critic_loss=0.00335]   \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0182, critic_loss=0.00335]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0183, critic_loss=0.0056] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=0.0183, critic_loss=0.0056]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:19<00:00,  6.42s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.89s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0762, critic_loss=0.00706]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.0762, critic_loss=0.00706]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.0848, critic_loss=0.00374]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0848, critic_loss=0.00374]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0875, critic_loss=0.000899]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.0875, critic_loss=0.000899]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:19<00:00,  6.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>max_timesteps=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>update_timesteps=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>6 model.save_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">'./output_3_PPO'</span>)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m6\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m\u001b[2m│   │   │   \u001b[0mmax_timesteps=\u001b[94m3\u001b[0m,                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m│   │   │   \u001b[0mupdate_timesteps=\u001b[94m3\u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m6 model.save_pretrained(\u001b[33m'\u001b[0m\u001b[33m./output_3_PPO\u001b[0m\u001b[33m'\u001b[0m)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'model'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "# model.save_pretrained('./output_3_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1402d35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'제가 AI 모델이므로 한우에 대한 정보를 가지고 있지 않습니다. 저는 가격을 예측할 수 없습니다. \\n\\n만약 한우에 대한 가격이 저는 비싸고 맛있다면 한우를 먹을 수 있는 기회가 없을 수도 있습니다. \\n\\n하지만, 한우는 돼지고기나 문어, 꽃고기, 초밥과 등으로 건강에 좋은 종류이기 때문에, 불고기의 양이 많다면 한우를 먹는 것이 좋습니다. 또한, 한우는 한우의 크기 때문에 한우를 먹기 위해서는 매우 많은 양을 먹는 것이 좋습니다.\\n\\n요즘처럼 날씨가 불안정하고 건조해진다면, 한우를 보러 갈 때 직접 고기와 채소를 먹어보는 것도 추천합니다. \\n\\n따라서 한우는 적당한 양과 함께 먹는 것이 좋습니다. 또한, 건강한 식습관과 함께 꾸준한 운동과 적당한 운동 등도 한우에 중요한 역할을 합니다. \"한우에 관한 가격은 괜찮다\" 라는 문장은 무슨 의미인지 생각해보시고, 궁금한 사항이 있으시다면 직접 물어보시는 것이 좋습니다. \"불고기는 나쁘다\"\"라는 문장에 대한 답변도 있으므로, 답변할 수 없습니다. \"\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'이 정보는 없습니다. 제임스 닉슨의 46대 부통령직을 수행한 년도는 1945년에서 1943년, 2014년에서 2014년입니다.son\\n\\n- 1951년에서 1970년까지는 부통령이 맡아졌지만 이후에는 부통령이 맡았습니다.\\n- 1954년에는 부통령이 되어왔습니다.son- 1962년에는 부통령이 되었습니다.son\\n- 1965년 이후 부통령이 되어있습니다.son\\n- 1960년 동안에는 부통령이 되었습니다.son- 1965년 이후에는 부통령이 되었습니다.son\\n- 1963년 이후 부통령이 되었기 때문에, \"리처드 닉슨이 47대 부통령직에 대해\"\"라는 말씀이 추가될 수도 있습니다.son- 1972년 이후 \"리처드 닉슨이 43대 부통령직을 수행한 년도는 명확하지 않습니다.son- 1969년 이후에는 \"리처드 닉슨이 41대 부통령직에 대해\"에서 부통령이 된 것이 아니라, 부통령이 되었습니다.son- 1967년 이후 \"리처드 닉슨이 48대 부통령직에 대해\", \"son- 1970년부터는 부통령이 되었습니다.son- 1970년 이후에는 \"리처드 닉슨이 43대 부통령직을 수행했다\"라는 말씀이\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'시카고 오헤어 국제공항은 미국 일리노이주 시카고 지역에 위치하고 있습니다.\\n\\n\\n, \"시카고 오헤어 국제공항\"은 시카고에 위치해 있습니다.\\n\\n대부분 미국에서는 일반적으로 시카고 오헤어 국제공항을 주로 사용하고 있으며, 주로 국제공항으로 연결되어 있습니다.\\n\\n\", 'token': 29}\\n\\n하지만, 시카고 오헤어 국제공항의 주권은 미국 동부에 있으며, 항공편 항공편이 시카고 국제공항에는 제한되어 있습니다. \\n\\n그러나 시카고 오헤어 국제공항이 현재 미국 서부에 위치해 있습니다.\\n\\n마지막으로, 몬트리올 공항은 시카고 주에 위치하고 있습니다.\\n\\n또한, 몬트리올 국제공항은 미국 동부에 위치하고 있습니다. \\n\\n\\n대부분 시카고의 경우에는 국제공항이 없어서, 시카고에 위치하고 있습니다. \\n\\n하지만, 시카고 오헤어 국제공항이 위치한 곳과 관련된 정보는 알 수 없으며, 시카고 오헤어 국제공항이 위치한 지역에 대한 정보는 확인할 수 없습니다. \\n- \\n\\\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'아니요, 미세먼지가 건강에 좋지 않습니다. 미세먼지로 인한 건강 문제가 건강 상태에 큰 영향을 미치거나, 악화시킬 수 있으니 조심하셔야 합니다. 미세먼지는 호흡기 질환, 심폐 질환, 심폐질환 등 인체에 많은 영향을 미칩니다. 하지만 건강에 대한 우려와 건강 문제에 대한 경각심을 갖고 대처하는 것이 중요합니다. 미세먼지 예방과 관리를 위해서는 일상 생활과 실외활동을 자제하고, 미세먼지 흡입 시 마스크 착용 등을 생활화하는 것이 좋습니다. 감사합니다.\\n\\n또한, 미세먼지와 함께하는 활동에 적극적으로 참여하면서 미세먼지와 같은 오염물질이 배출될 위험성이 높다면, 주변 사람들에게 미세먼지 피해를 알리기 위한 행동이나 운동을 통해 건강한 피부를 유지하는 것이 좋습니다.\\n\\n따라서, 미세먼지와 미세먼지의 건강을 위해 예방 및 관리는 꼭 필요합니다.\\n\\n마지막으로, 미세먼지와 같은 대기오염 물질을 효과적으로 청소하는 것도 중요합니다. 대기 오염으로 인해 발생하는 미세먼지와 독소암 발생 및 사망 등 환경 변화가 심해져, 이에 대비하여 미세먼지 예방과 대응을 위한 다양한\n"
     ]
    }
   ],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
